{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller Pr치ctico: 츼rboles de Decisi칩n con Scikit-Learn\n",
    "\n",
    "**Objetivos de la Pr치ctica:**\n",
    "\n",
    "En este taller, aplicaremos los conceptos te칩ricos de los 치rboles de decisi칩n. Al finalizar, ser치s capaz de:\n",
    "\n",
    "1.  **Cargar y preparar datos** para un problema de clasificaci칩n.\n",
    "2.  **Entrenar un 치rbol de decisi칩n** utilizando la librer칤a `scikit-learn`.\n",
    "3.  **Visualizar e interpretar** la estructura de un 치rbol.\n",
    "4.  Identificar y comprender el problema del **sobreajuste** en los 치rboles.\n",
    "5.  Aplicar la **poda por complejidad de costo** para encontrar un 치rbol m치s robusto.\n",
    "6.  Evaluar la **importancia de las caracter칤sticas** que el modelo aprende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparaci칩n del Entorno\n",
    "\n",
    "Primero, importaremos las librer칤as que necesitaremos para nuestro an치lisis. Usaremos `pandas` para la manipulaci칩n de datos, `scikit-learn` para el modelado, `plotly` para visualizaciones interactivas y `matplotlib` para la visualizaci칩n espec칤fica del 치rbol."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Librer칤as para manipulaci칩n y an치lisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librer칤as para modelado y evaluaci칩n\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Librer칤as para visualizaci칩n\n",
    "import plotly.express as px\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci칩n de Datos\n",
    "\n",
    "Vamos a utilizar el dataset de **C치ncer de Mama de Wisconsin**, que est치 convenientemente incluido en `scikit-learn`. Es un problema de clasificaci칩n binaria cl치sico donde el objetivo es predecir si un tumor es maligno o benigno bas치ndose en varias caracter칤sticas de sus c칠lulas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cargamos el dataset. `as_frame=True` nos lo devuelve como un DataFrame de pandas.\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# Separamos las caracter칤sticas (X) y la variable objetivo (y)\n",
    "X = df[data.feature_names]\n",
    "y = df['target']\n",
    "\n",
    "# Nombres de las clases (0: Maligno, 1: Benigno)\n",
    "print(f\"Nombres de las clases: {data.target_names}\")\n",
    "\n",
    "# Echamos un vistazo a las primeras filas del dataset\n",
    "print(\"\\nPrimeras 5 filas de caracter칤sticas:\")\n",
    "display(X.head())\n",
    "\n",
    "# Resumen del dataset\n",
    "print(\"\\nInformaci칩n del DataFrame:\")\n",
    "X.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.value_counts().plot(kind='bar', title='Distribuci칩n de Clases')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci칩n Exploratoria\n",
    "Usemos Plotly para visualizar la relaci칩n entre dos caracter칤sticas importantes, `mean radius` y `mean texture`, y ver c칩mo se distribuyen las clases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_to_plot = df.copy()\n",
    "df_to_plot['target'] = df_to_plot['target'].map({i: name for i, name in enumerate(data.target_names)})\n",
    "fig = px.scatter(\n",
    "    df_to_plot,\n",
    "    x='mean radius', \n",
    "    y='mean texture', \n",
    "    color='target', \n",
    "    #color_continuous_scale='reds_r',\n",
    "    title='Distribuci칩n de Clases por Radio y Textura Promedio',\n",
    "    labels={'target': 'Clase', 'mean radius': 'Radio Promedio', 'mean texture': 'Textura Promedia'}\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de un 츼rbol de Decisi칩n (Sin Poda)\n",
    "\n",
    "Ahora, dividiremos nuestros datos en un conjunto de entrenamiento y uno de prueba. Luego, entrenaremos un 치rbol de decisi칩n sin ninguna restricci칩n de crecimiento para observar el fen칩meno del sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dividimos los datos: 80% para entrenamiento, 20% para prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos el clasificador sin restricciones de profundidad\n",
    "tree_overfit = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "tree_overfit.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el rendimiento\n",
    "y_train_pred = tree_overfit.predict(X_train)\n",
    "y_test_pred = tree_overfit.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Precisi칩n en el set de ENTRENAMIENTO: {train_accuracy:.4f}\")\n",
    "print(f\"Precisi칩n en el set de PRUEBA: {test_accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Observaci칩n:** 춰El modelo tiene una precisi칩n del 100% en los datos de entrenamiento! Esto es una se침al clara de sobreajuste. El 치rbol ha crecido tanto que ha \"memorizado\" cada punto de entrenamiento, pero su rendimiento en los datos de prueba, aunque bueno, es menor."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci칩n del 츼rbol Sobreajustado\n",
    "Veamos qu칠 tan complejo es este 치rbol. La funci칩n `plot_tree` nos ayuda a visualizarlo. Usamos `matplotlib` para esta tarea, ya que `plot_tree` est치 construida sobre ella."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(tree_overfit, \n",
    "          feature_names=data.feature_names, \n",
    "          class_names=data.target_names, \n",
    "          filled=True,\n",
    "          fontsize=8)\n",
    "plt.title(\"츼rbol de Decisi칩n Sin Poda (Sobreajustado)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, el 치rbol es enorme e ininterpretable. Necesitamos una forma de simplificarlo: la poda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Poda por Complejidad de Costo (Cost-Complexity Pruning)\n",
    "\n",
    "La poda por complejidad de costo es una estrategia para encontrar el sub-치rbol que mejor generaliza. Funciona penalizando el tama침o del 치rbol. El par치metro clave es `ccp_alpha` (el $\\alpha$ que vimos en la teor칤a).\n",
    "\n",
    "El proceso es:\n",
    "1.  Calcular la ruta de poda: obtener los valores de `ccp_alpha` que generan diferentes sub-치rboles.\n",
    "2.  Usar validaci칩n cruzada para encontrar el mejor valor de `ccp_alpha`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Calcular la ruta de poda\n",
    "path = tree_overfit.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Excluimos el alpha m치ximo que eliminar칤a todo el 치rbol\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "# 2. Encontrar el mejor alpha con Validaci칩n Cruzada\n",
    "param_grid = {'ccp_alpha': ccp_alphas}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = grid_search.best_params_['ccp_alpha']\n",
    "print(f\"Mejor valor de ccp_alpha encontrado: {best_alpha:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento y Evaluaci칩n del 츼rbol 칍ptimo\n",
    "\n",
    "Ahora que tenemos el mejor valor de `ccp_alpha`, entrenamos un nuevo 치rbol con ese par치metro y evaluamos su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# El GridSearchCV con refit=True (por defecto) ya ha re-entrenado el mejor modelo\n",
    "tree_pruned = grid_search.best_estimator_\n",
    "\n",
    "# Evaluamos el nuevo modelo podado\n",
    "y_train_pred_p = tree_pruned.predict(X_train)\n",
    "y_test_pred_p = tree_pruned.predict(X_test)\n",
    "\n",
    "train_accuracy_p = accuracy_score(y_train, y_train_pred_p)\n",
    "test_accuracy_p = accuracy_score(y_test, y_test_pred_p)\n",
    "\n",
    "print(\"--- 츼rbol Sobreajustado ---\")\n",
    "print(f\"Precisi칩n en Entrenamiento: {train_accuracy:.4f}\")\n",
    "print(f\"Precisi칩n en Prueba: {test_accuracy:.4f}\")\n",
    "print(\"\\n--- 츼rbol Podado ---\")\n",
    "print(f\"Precisi칩n en Entrenamiento: {train_accuracy_p:.4f}\")\n",
    "print(f\"Precisi칩n en Prueba: {test_accuracy_p:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An치lisis de Resultados:** El 치rbol podado tiene una precisi칩n de entrenamiento m치s baja (ya no es 100%), lo cual es bueno, significa que no est치 memorizando. Sin embargo, su precisi칩n en el conjunto de prueba es mayor. 춰Hemos creado un modelo m치s simple y que generaliza mejor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci칩n del 츼rbol Podado\n",
    "Veamos ahora nuestro nuevo 치rbol, mucho m치s simple e interpretable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree_pruned, \n",
    "          feature_names=data.feature_names, \n",
    "          class_names=data.target_names, \n",
    "          filled=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"츼rbol de Decisi칩n Podado con ccp_alpha 칍ptimo\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Importancia de las Caracter칤sticas\n",
    "\n",
    "Finalmente, podemos extraer qu칠 caracter칤sticas consider칩 m치s importantes nuestro 치rbol podado para tomar sus decisiones. Esto se basa en la reducci칩n total del 칤ndice de Gini que cada caracter칤stica aporta.\n",
    "\n",
    "La importancia de las caracter칤sticas en los 치rboles de decisi칩n se calcula midiendo cu치nto reduce cada caracter칤stica la impureza (como la impureza de Gini o la entrop칤a) en todos los nodos donde se utiliza para dividir los datos. La importancia de cada caracter칤stica es la suma de las reducciones de impureza que aporta, ponderada por la cantidad de muestras que divide, y normalizada para que todas las importancias sumen 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': tree_pruned.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    importances,\n",
    "    x='feature',\n",
    "    y='importance',\n",
    "    title='Importancia de las Caracter칤sticas en el 츼rbol Podado',\n",
    "    labels={'feature': 'Caracter칤stica', 'importance': 'Importancia (Reducci칩n de Gini)'}\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Desaf칤os y Experimentaci칩n 游\n",
    "\n",
    "Ahora es tu turno de experimentar. Intenta responder a las siguientes preguntas modificando el c칩digo anterior:\n",
    "\n",
    "1.  **Cambia el Criterio:** En lugar de `'gini'`, entrena un 치rbol usando `'entropy'` como criterio. 쮺ambia mucho el 치rbol podado final? 쯏 la importancia de las caracter칤sticas?\n",
    "2.  **Poda por Profundidad:** En lugar de usar `ccp_alpha`, intenta controlar el sobreajuste con el hiperpar치metro `max_depth`. Usa `GridSearchCV` para encontrar la profundidad 칩ptima. 쯈u칠 m칠todo da mejores resultados en el set de prueba: poda por complejidad o por profundidad m치xima?\n",
    "3.  **Estabilidad del Modelo:** Cambia el `random_state` en `train_test_split` a otro n칰mero (o qu칤talo). Vuelve a correr todo el notebook. 쮼l 치rbol final y la precisi칩n cambian mucho? Esto te dar치 una idea de la inestabilidad de los 치rboles de decisi칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 游닇 Ejercicios Adicionales\n",
    "\n",
    "Para solidificar tu aprendizaje, te proponemos los siguientes ejercicios para que explores por tu cuenta:\n",
    "\n",
    "1.  **Otro Dataset de Clasificaci칩n:** Repite el an치lisis completo de este notebook (entrenamiento, poda, visualizaci칩n) pero con el dataset de **Vinos** de `scikit-learn` (`sklearn.datasets.load_wine`). Es un problema con 3 clases.\n",
    "\n",
    "2.  **츼rboles de Regresi칩n:** Importa el dataset de **Viviendas de California** (`sklearn.datasets.fetch_california_housing`). Entrena un `DecisionTreeRegressor` para predecir el valor de las viviendas. El criterio de divisi칩n por defecto es el error cuadr치tico medio (`'squared_error'`). 쮺칩mo interpretas el 치rbol resultante?\n",
    "\n",
    "3.  **An치lisis de Hiperpar치metros:** Investiga el efecto de `min_samples_split` y `min_samples_leaf`. Usa `GridSearchCV` para encontrar la mejor combinaci칩n de `max_depth`, `min_samples_split` y `min_samples_leaf` para el dataset de c치ncer. 쯄ejora el resultado de la poda por complejidad?\n",
    "\n",
    "4.  **Visualizaci칩n de Fronteras de Decisi칩n:** Usando solo dos caracter칤sticas (ej. `mean radius` y `mean texture`), entrena un 치rbol simple (ej. `max_depth=3`). Investiga c칩mo crear un gr치fico de contorno (contour plot) para visualizar las \"cajas\" o fronteras de decisi칩n que el 치rbol crea en el espacio 2D.\n",
    "\n",
    "5.  **Sensibilidad a la Escala:** Aunque se dijo que los 치rboles no son sensibles a la escala, compru칠balo. Aplica un `StandardScaler` de `scikit-learn` a los datos `X` antes de entrenar el 치rbol. 쮺ambia la estructura del 치rbol o su rendimiento? 쯇or qu칠 s칤 o por qu칠 no?\n",
    "\n",
    "6.  **Interpreta una Ruta de Decisi칩n:** En el 치rbol podado final, elige una hoja y traza la ruta desde el nodo ra칤z hasta ella. Escribe en texto plano la secuencia de reglas que definen esa hoja. (Ej: \"Si `worst radius <= 16.5` Y `worst concave points <= 0.142`...\").\n",
    "\n",
    "7.  **Comparaci칩n de M칠tricas de Impureza:** En el 치rbol podado con Gini, anota la importancia de las 5 caracter칤sticas principales. Ahora, fuerza el entrenamiento y la poda usando `'entropy'` como criterio. Compara la nueva lista de las 5 caracter칤sticas m치s importantes. 쯉on las mismas? 쮼n el mismo orden?\n",
    "\n",
    "8.  **Efecto del Tama침o del Test Set:** Vuelve a ejecutar el an치lisis, pero esta vez con `test_size=0.4`. 쮺칩mo afecta un conjunto de prueba m치s grande a la evaluaci칩n del rendimiento y a la confianza que tienes en tu modelo?\n",
    "\n",
    "9.  **Explora la Salida de `cost_complexity_pruning_path`:** La variable `path` que creamos contiene `ccp_alphas` e `impurities`. Grafica `impurities` vs `ccp_alphas`. 쯈u칠 te dice este gr치fico sobre c칩mo la pureza del 치rbol se ve afectada por el par치metro de poda?\n",
    "\n",
    "10. **Impacto de una Caracter칤stica Ruidosa:** A침ade una nueva columna a `X_train` y `X_test` con datos completamente aleatorios (ej. `np.random.rand(n_samples, 1)`). Vuelve a entrenar el modelo y a calcular la importancia de caracter칤sticas. 쮸parece la nueva caracter칤stica \"ruidosa\" como importante? 쯈u칠 te dice esto sobre los 치rboles?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
